{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabalho-Visao-Computacional-UFPR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "11788d199534453b3091baa8e21d49a7afe3aaf89a016b3a09f594b82a19522e"
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHugcVTny6qp"
      },
      "source": [
        "# Descrição do Trabalho\n",
        "O arquivo trabalho.zip possui imagens de leucócitos na parte central. As imagens são nomeadas como \"ImXXX_Y_Z.jpg\". Onde ImXXX é o número da imagem, Y é o seu número da sequência de alteração (data augmentation) e Z a sua classe (0 ou 1). Onde, 0 indica paciente normal e 1 pacientes com leucemia.\n",
        "\n",
        "Utilizando técnicas de Visão Computacional e/ou CNNS extraia características das imagens e faça a sua correta classificação (0 ou 1). Lembre-se de separar os grupos de treinamento e teste. Você pode utilizar a técnica de k-folds para a divisão das imagens e evitar o overfitting.\n",
        "\n",
        "Entregue um arquivo zip com um relatório do seu trabalho, o(s) código(s) fonte(s) e um README indicando como o seu trabalho funciona. Você pode fazer no Colab e disponibilizar o arquivo fonte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "from src.model import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versão do TensorFlow: 2.4.0\n",
            "Versão do Keras: 2.4.3\n",
            "Num GPUs Available: 0\n",
            "SET IMAGES PATH\n",
            "Train PATH: x:\\Git\\cnn-leucemia\\data\\train\n",
            "Test PATH: x:\\Git\\cnn-leucemia\\data\\test\n",
            "Vaidation PATH: x:\\Git\\cnn-leucemia\\data\\val\n",
            "SET DATA\n",
            "Found 3821 images belonging to 2 classes.\n",
            "Found 819 images belonging to 2 classes.\n",
            "Found 820 images belonging to 2 classes.\n",
            "TRAIN PREDICT MODEL\n",
            "TRAIN MODEL\n",
            "Epoch 1/5\n",
            "120/120 [==============================] - 30s 242ms/step - loss: 0.6778 - fn: 294.2727 - accuracy: 0.5829 - recall: 0.6697 - val_loss: 0.4578 - val_fn: 65.0000 - val_accuracy: 0.7631 - val_recall: 0.8474\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 28s 234ms/step - loss: 0.4619 - fn: 160.0496 - accuracy: 0.7707 - recall: 0.8321 - val_loss: 0.3718 - val_fn: 96.0000 - val_accuracy: 0.8242 - val_recall: 0.7746\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 28s 236ms/step - loss: 0.4021 - fn: 129.8182 - accuracy: 0.8090 - recall: 0.8619 - val_loss: 0.2821 - val_fn: 11.0000 - val_accuracy: 0.8645 - val_recall: 0.9742\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 28s 236ms/step - loss: 0.2835 - fn: 101.2727 - accuracy: 0.8805 - recall: 0.8953 - val_loss: 0.2109 - val_fn: 44.0000 - val_accuracy: 0.9133 - val_recall: 0.8967\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 28s 235ms/step - loss: 0.2033 - fn: 85.1901 - accuracy: 0.9098 - recall: 0.9040 - val_loss: 0.1552 - val_fn: 30.0000 - val_accuracy: 0.9389 - val_recall: 0.9296\n",
            "INFO:tensorflow:Assets written to: saved_model\\assets\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 54, 54, 64)        23296     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 27, 27, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 23, 23, 64)        102464    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 10, 128)       32896     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 9, 128)         65664     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,536,577\n",
            "Trainable params: 1,536,577\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "PREDICT MODEL\n",
            "26/26 [==============================] - 2s 58ms/step - loss: 0.1567 - fn: 24.0000 - accuracy: 0.9402 - recall: 0.9438\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.set_images_path()\n",
        "model.set_data()\n",
        "model.set_model()\n",
        "model.train_and_predict(epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PLOT TEST METRICS\nAccuracy: 0.526\nRecall: 0.546\n"
          ]
        }
      ],
      "source": [
        "model.plot_test_metrics()"
      ]
    },
    {
      "source": [
        "Accuracy: 0.526\n",
        "Recall: 0.546\n",
        "\n",
        "Accuracy: 0.526\n",
        "Recall: 0.546\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}