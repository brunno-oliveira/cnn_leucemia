{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabalho-Visao-Computacional-UFPR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "11788d199534453b3091baa8e21d49a7afe3aaf89a016b3a09f594b82a19522e"
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHugcVTny6qp"
      },
      "source": [
        "# Descrição do Trabalho\n",
        "O arquivo trabalho.zip possui imagens de leucócitos na parte central. As imagens são nomeadas como \"ImXXX_Y_Z.jpg\". Onde ImXXX é o número da imagem, Y é o seu número da sequência de alteração (data augmentation) e Z a sua classe (0 ou 1). Onde, 0 indica paciente normal e 1 pacientes com leucemia.\n",
        "\n",
        "Utilizando técnicas de Visão Computacional e/ou CNNS extraia características das imagens e faça a sua correta classificação (0 ou 1). Lembre-se de separar os grupos de treinamento e teste. Você pode utilizar a técnica de k-folds para a divisão das imagens e evitar o overfitting.\n",
        "\n",
        "Entregue um arquivo zip com um relatório do seu trabalho, o(s) código(s) fonte(s) e um README indicando como o seu trabalho funciona. Você pode fazer no Colab e disponibilizar o arquivo fonte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "from src.model import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versão do TensorFlow: 2.4.0\n",
            "Versão do Keras: 2.4.3\n",
            "Num GPUs Available: 0\n",
            "SET IMAGES PATH\n",
            "Train PATH: x:\\Git\\cnn-leucemia\\data\\train\n",
            "Test PATH: x:\\Git\\cnn-leucemia\\data\\test\n",
            "Vaidation PATH: x:\\Git\\cnn-leucemia\\data\\val\n",
            "SET DATA\n",
            "Found 3821 images belonging to 2 classes.\n",
            "Found 819 images belonging to 2 classes.\n",
            "Found 820 images belonging to 2 classes.\n",
            "TRAIN PREDICT MODEL\n",
            "TRAIN MODEL\n",
            "Epoch 1/5\n",
            "120/120 [==============================] - 37s 299ms/step - loss: 0.6439 - fn: 289.3306 - accuracy: 0.6199 - recall: 0.6796 - val_loss: 0.4288 - val_fn: 48.0000 - val_accuracy: 0.7900 - val_recall: 0.8873\n",
            "Epoch 2/5\n",
            "120/120 [==============================] - 20s 167ms/step - loss: 0.4417 - fn: 138.9587 - accuracy: 0.7746 - recall: 0.8445 - val_loss: 0.3589 - val_fn: 98.0000 - val_accuracy: 0.8352 - val_recall: 0.7700\n",
            "Epoch 3/5\n",
            "120/120 [==============================] - 20s 164ms/step - loss: 0.3745 - fn: 121.0826 - accuracy: 0.8153 - recall: 0.8679 - val_loss: 0.2992 - val_fn: 37.0000 - val_accuracy: 0.8681 - val_recall: 0.9131\n",
            "Epoch 4/5\n",
            "120/120 [==============================] - 20s 164ms/step - loss: 0.3131 - fn: 128.6612 - accuracy: 0.8501 - recall: 0.8611 - val_loss: 0.2552 - val_fn: 73.0000 - val_accuracy: 0.8767 - val_recall: 0.8286\n",
            "Epoch 5/5\n",
            "120/120 [==============================] - 20s 168ms/step - loss: 0.2744 - fn: 108.5372 - accuracy: 0.8746 - recall: 0.8836 - val_loss: 0.2429 - val_fn: 30.0000 - val_accuracy: 0.8877 - val_recall: 0.9296\n",
            "INFO:tensorflow:Assets written to: saved_model\\assets\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 54, 54, 64)        7808      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 27, 27, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 23, 23, 64)        102464    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 10, 128)       32896     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 9, 128)         65664     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,521,089\n",
            "Trainable params: 1,521,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "PREDICT MODEL\n",
            "26/26 [==============================] - 4s 170ms/step - loss: 0.2748 - fn: 35.0000 - accuracy: 0.8683 - recall: 0.9180\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.set_images_path()\n",
        "model.set_data()\n",
        "model.set_model()\n",
        "model.train_and_predict(epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PLOT TEST METRICS\nAccuracy: 0.502\nRecall: 0.567\n"
          ]
        }
      ],
      "source": [
        "model.plot_test_metrics()"
      ]
    },
    {
      "source": [
        "#### EPOCHS: 10\n",
        "\n",
        "Accuracy: 0.512\n",
        "Recall: 0.595\n",
        "\n",
        "\n",
        "Accuracy: 0.513\n",
        "Recall: 0.562"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}